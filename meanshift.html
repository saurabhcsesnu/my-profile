<!DOCTYPE html>
<html lang="en" class="scroll-smooth">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Interactive Report: NumPy to PyTorch Meanshift Vectorization</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <!-- Chosen Palette: Slate & Amber -->
    <!-- Application Structure Plan: A single-page, scrolling narrative application divided into thematic sections. A sticky top navigation allows users to jump to any topic, facilitating both linear reading and targeted exploration. The structure is designed to first present the problem (NumPy inefficiency), then the conceptual solution (vectorization), followed by a step-by-step interactive breakdown of the PyTorch implementation, a visual performance comparison, and finally, deeper discussion points and the full code. This user flow transforms a dense report into an engaging learning path, prioritizing understanding of the 'why' before diving into the 'how', which is more effective for technical education than a simple chapter-by-chapter layout. -->
    <!-- Visualization & Content Choices:
        - The Challenge (NumPy): Goal: Inform about sequential processing bottlenecks. Method: A side-by-side view with pseudo-code and a CSS/JS animation of a single-pixel scan. Interaction: Highlighting the sequential, slow nature. Justification: Visually contrasts with the parallel approach shown later.
        - The Solution (PyTorch): Goal: Explain vectorization with `unfold`. Method: HTML/CSS diagram of an image being broken into patches. Interaction: A slider to change window size demonstrates the concept's flexibility. Justification: Makes the abstract 'unfold' operation concrete.
        - Step-by-Step Breakdown: Goal: Organize and explain the implementation. Method: A tabbed interface with HTML/CSS diagrams for each stage (Feature Tensor, Weighting, etc.). Interaction: Clicking tabs reveals each step in a controlled sequence. Justification: Breaks a complex algorithm into digestible, user-paced chunks.
        - Performance: Goal: Compare NumPy vs. PyTorch. Method: A dynamic bar chart. Library: Chart.js. Interaction: Sliders for 'Image Size' and 'Iterations' update the chart. Justification: Quantifies the "why" of this entire effort in a powerful, interactive way.
        - Deep Dive (FAQ): Goal: Organize detailed discussion points. Method: Accordion/collapsible list. Interaction: Clicking a question reveals the answer. Justification: Provides depth on-demand without cluttering the main narrative.
        - CONFIRMING NO SVG/Mermaid. -->
    <!-- CONFIRMATION: NO SVG graphics used. NO Mermaid JS used. -->
    <style>
        body { font-family: 'Inter', sans-serif; }
        .nav-active { color: #f59e0b; font-weight: 600; }
        .nav-inactive { color: #94a3b8; }
        .tab-active { background-color: #f59e0b; color: #ffffff; }
        .tab-inactive { background-color: #e2e8f0; color: #475569; }
        .diagram-box { border: 2px dashed #cbd5e1; background-color: #f8fafc; }
        .code-block { background-color: #1e293b; color: #e2e8f0; font-family: 'Courier New', Courier, monospace; }
        .scanner-line {
            position: absolute;
            width: 100%;
            height: 2px;
            background-color: #f59e0b;
            animation: scan 4s linear infinite;
        }
        @keyframes scan {
            0% { top: 0; }
            100% { top: 100%; }
        }
        .patch {
            transition: all 0.2s ease-in-out;
        }
        .chart-container {
            position: relative;
            width: 100%;
            max-width: 800px;
            margin-left: auto;
            margin-right: auto;
            height: 40vh;
            max-height: 450px;
        }
    </style>
</head>
<body class="bg-slate-50 text-slate-700">

    <nav class="sticky top-0 z-50 bg-white/80 backdrop-blur-md shadow-md">
        <div class="container mx-auto px-4">
            <div class="flex items-center justify-between h-16">
                <h1 class="text-xl font-bold text-slate-800">Meanshift Vectorization</h1>
                <div class="hidden md:flex items-center space-x-4 lg:space-x-6 text-sm font-medium">
                    <a href="#overview" class="nav-link nav-inactive hover:text-amber-500 transition-colors">Overview</a>
                    <a href="#challenge" class="nav-link nav-inactive hover:text-amber-500 transition-colors">The Challenge</a>
                    <a href="#solution" class="nav-link nav-inactive hover:text-amber-500 transition-colors">The Solution</a>
                    <a href="#step-by-step" class="nav-link nav-inactive hover:text-amber-500 transition-colors">Step-by-Step</a>
                    <a href="#performance" class="nav-link nav-inactive hover:text-amber-500 transition-colors">Performance</a>
                    <a href="#code" class="nav-link nav-inactive hover:text-amber-500 transition-colors">Full Code</a>
                    <a href="#deep-dive" class="nav-link nav-inactive hover:text-amber-500 transition-colors">Deep Dive</a>
                </div>
            </div>
        </div>
    </nav>

    <main class="container mx-auto p-4 md:p-8">

        <!-- Overview Section -->
        <section id="overview" class="py-16">
            <div class="text-center mb-12">
                <h2 class="text-4xl font-bold text-slate-800 mb-4">From Slow Loops to Lightning-Fast Tensors</h2>
                <p class="max-w-3xl mx-auto text-lg text-slate-600">This interactive report explores the process of converting a classic, loop-based Meanshift filtering algorithm from NumPy to a highly efficient, vectorized PyTorch implementation. Discover how replacing sequential operations with parallel tensor computations unlocks massive performance gains, especially on modern hardware like GPUs.</p>
            </div>
             <div class="max-w-4xl mx-auto p-6 bg-white rounded-xl shadow-lg">
                <p class="text-center font-semibold text-slate-800 mb-4">The Core Transformation</p>
                <div class="grid md:grid-cols-3 items-center gap-6">
                    <div class="text-center">
                        <div class="p-4 bg-red-100 rounded-lg">
                            <h3 class="font-bold text-red-800">NumPy (The Challenge)</h3>
                            <p class="text-sm text-red-700">Sequential pixel-by-pixel processing using slow Python loops.</p>
                        </div>
                    </div>
                    <div class="text-center text-5xl font-extrabold text-amber-500">&rarr;</div>
                    <div class="text-center">
                         <div class="p-4 bg-green-100 rounded-lg">
                            <h3 class="font-bold text-green-800">PyTorch (The Solution)</h3>
                            <p class="text-sm text-green-700">Parallel patch-based processing using vectorized tensor operations.</p>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!-- The Challenge Section -->
        <section id="challenge" class="py-16 bg-white rounded-2xl shadow-lg my-8">
            <div class="max-w-6xl mx-auto px-6">
                <div class="text-center mb-12">
                    <h2 class="text-3xl font-bold text-slate-800 mb-2">The Challenge: The Inefficiency of Loops</h2>
                    <p class="text-lg text-slate-600">The original NumPy implementation, while conceptually simple, suffers from a major performance bottleneck: nested `for` loops. It processes every single pixel and its neighbors one by one, failing to utilize the parallel processing power of modern CPUs and GPUs.</p>
                </div>
                <div class="grid md:grid-cols-2 gap-8 items-center">
                    <div>
                        <h3 class="font-semibold text-xl mb-4 text-slate-800">Sequential Processing Logic</h3>
                        <div class="code-block p-4 rounded-lg text-sm">
                            <pre>for iter in range(ITER):
  for i in range(height):
    for j in range(width):
      # Define neighborhood
      # Loop through neighbors
      for p in neighbors_y:
        for q in neighbors_x:
          # Calculate weight
          # ...
      # Update pixel (i,j)
      # ...</pre>
                        </div>
                        <p class="mt-4 text-slate-600">This sequential approach means the total execution time is a product of iterations, image height, width, and neighborhood size—a recipe for slow processing on large images.</p>
                    </div>
                    <div class="flex flex-col items-center">
                         <h3 class="font-semibold text-xl mb-4 text-slate-800">Visualizing the Bottleneck</h3>
                        <div class="relative w-48 h-48 bg-slate-200 grid grid-cols-8 grid-rows-8 gap-px p-1 rounded-md overflow-hidden">
                            <div class="scanner-line"></div>
                            <script>
                                for(let i=0; i<64; i++) {
                                    document.currentScript.parentElement.innerHTML += `<div class="bg-slate-300"></div>`;
                                }
                            </script>
                        </div>
                        <p class="mt-4 text-center text-slate-600">The animation simulates how the code "scans" the image pixel by pixel, a fundamentally slow process.</p>
                    </div>
                </div>
            </div>
        </section>

        <!-- The Solution Section -->
        <section id="solution" class="py-16">
            <div class="max-w-6xl mx-auto px-6">
                <div class="text-center mb-12">
                    <h2 class="text-3xl font-bold text-slate-800 mb-2">The Solution: Vectorization with `unfold`</h2>
                    <p class="text-lg text-slate-600">PyTorch's tensor-based operations allow us to rethink the problem. Instead of looping, we can treat the entire image and its neighborhoods as a single large tensor. The key is the `unfold` operation, which extracts all local patches from an image simultaneously.</p>
                </div>
                <div class="grid md:grid-cols-2 gap-8 items-center">
                    <div class="flex flex-col items-center">
                        <h3 class="font-semibold text-xl mb-4 text-slate-800">Parallel Patch Extraction</h3>
                        <div id="unfold-diagram" class="relative w-64 h-64 bg-slate-200 grid grid-cols-8 grid-rows-8 gap-px p-1 rounded-md">
                            <!-- Patches will be generated by JS -->
                        </div>
                        <p class="mt-4 text-center text-slate-600">`unfold` creates a "view" of the data where every neighborhood is ready for parallel processing.</p>
                    </div>
                    <div>
                        <h3 class="font-semibold text-xl mb-4 text-slate-800">Interactive Control</h3>
                        <div class="bg-white p-6 rounded-lg shadow-md">
                            <label for="wsize-slider" class="font-medium text-slate-700">Window Size: <span id="wsize-label" class="font-bold text-amber-600">3x3</span></label>
                            <input id="wsize-slider" type="range" min="3" max="7" step="2" value="3" class="w-full h-2 bg-slate-200 rounded-lg appearance-none cursor-pointer">
                            <p class="mt-4 text-slate-600">Adjust the slider to see how `unfold` works with different neighborhood sizes. This entire operation happens in a single, highly optimized step in PyTorch, replacing millions of individual loop iterations.</p>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!-- Step-by-Step Section -->
        <section id="step-by-step" class="py-16 bg-white rounded-2xl shadow-lg my-8">
             <div class="max-w-6xl mx-auto px-6">
                <div class="text-center mb-12">
                    <h2 class="text-3xl font-bold text-slate-800 mb-2">A Step-by-Step Breakdown of the PyTorch Logic</h2>
                    <p class="text-lg text-slate-600">The vectorized implementation involves a sequence of tensor manipulations. Click through the tabs to see how we build up from a simple image to a fully filtered result, all without a single explicit pixel loop.</p>
                </div>

                <div>
                    <div class="flex flex-wrap justify-center border-b border-slate-200 mb-8">
                        <button class="step-tab tab-active px-4 py-2 font-semibold rounded-t-lg transition-colors" data-step="1">1. Feature Tensor</button>
                        <button class="step-tab tab-inactive px-4 py-2 font-semibold rounded-t-lg transition-colors" data-step="2">2. Unfold</button>
                        <button class="step-tab tab-inactive px-4 py-2 font-semibold rounded-t-lg transition-colors" data-step="3">3. Weighting</button>
                        <button class="step-tab tab-inactive px-4 py-2 font-semibold rounded-t-lg transition-colors" data-step="4">4. Averaging</button>
                        <button class="step-tab tab-inactive px-4 py-2 font-semibold rounded-t-lg transition-colors" data-step="5">5. Interpolation</button>
                    </div>

                    <div id="step-content" class="grid md:grid-cols-2 gap-8 items-center min-h-[350px]">
                        <!-- Content will be injected by JS -->
                    </div>
                </div>
            </div>
        </section>

        <!-- Performance Section -->
        <section id="performance" class="py-16">
            <div class="max-w-5xl mx-auto px-6">
                <div class="text-center mb-12">
                    <h2 class="text-3xl font-bold text-slate-800 mb-2">The "Why": A Massive Performance Leap</h2>
                    <p class="text-lg text-slate-600">The theoretical difference in performance is staggering. Vectorization on a GPU can be orders of magnitude faster than sequential processing on a CPU. Interact with the controls below to see how the performance gap widens as the workload increases.</p>
                </div>
                <div class="bg-white p-6 rounded-xl shadow-lg">
                    <div class="grid md:grid-cols-2 gap-6 mb-6">
                        <div>
                            <label for="image-size-slider" class="font-medium">Image Size (pixels): <span id="image-size-label" class="font-bold text-amber-600">250,000</span></label>
                            <input id="image-size-slider" type="range" min="50000" max="5000000" step="50000" value="250000" class="w-full">
                        </div>
                        <div>
                            <label for="iterations-slider" class="font-medium">Iterations: <span id="iterations-label" class="font-bold text-amber-600">5</span></label>
                            <input id="iterations-slider" type="range" min="1" max="20" step="1" value="5" class="w-full">
                        </div>
                    </div>
                    <div class="chart-container">
                        <canvas id="perfChart"></canvas>
                    </div>
                </div>
            </div>
        </section>

        <!-- Full Code Section -->
        <section id="code" class="py-16 bg-white rounded-2xl shadow-lg my-8">
            <div class="max-w-4xl mx-auto px-6">
                <div class="text-center mb-12">
                     <h2 class="text-3xl font-bold text-slate-800 mb-2">The Complete PyTorch Implementation</h2>
                     <p class="text-lg text-slate-600">Here is the complete, documented Python function for the vectorized meanshift filter. Note the absence of explicit loops for pixel processing.</p>
                </div>
                <div class="code-block p-4 rounded-lg text-xs overflow-x-auto max-h-[500px]">
                <pre>
import torch
import torch.nn.functional as F
from sklearn.neighbors import KNeighborsRegressor
import numpy as np

def meanshift_pytorch(image_np: np.ndarray, wsize: int, sigma_int: float,
                      sigma_sp: float, ITER: int, step_size: int = 1,
                      device: str = 'cpu') -> torch.Tensor:
    if wsize % 2 == 0:
        raise ValueError("wsize must be odd")

    # 1. Input Preparation
    image_tensor = torch.from_numpy(image_np.astype(np.float32)).permute(2, 0, 1).unsqueeze(0).to(device)
    b, c, h, w = image_tensor.shape

    # 2. Coordinate Grid
    grid_y, grid_x = torch.meshgrid(torch.arange(h, device=device),
                                    torch.arange(w, device=device),
                                    indexing='ij')
    coords = torch.stack((grid_y, grid_x), dim=0).unsqueeze(0).float()

    # 3. Feature Tensor (Intensity + Coords)
    current_features = torch.cat((image_tensor, coords), dim=1)

    # 4. Patch Extraction Setup (`unfold`)
    padding = wsize // 2
    unfold = torch.nn.Unfold(kernel_size=wsize, padding=0, stride=step_size)
    pad_op = torch.nn.ReflectionPad2d(padding)

    # 5. Iterative Meanshift Update
    with torch.no_grad():
        for _ in range(ITER):
            features_padded = pad_op(current_features)
            features_unfolded = unfold(features_padded)

            kh, kw = wsize, wsize
            h_out = (h + 2 * padding - (kh - 1) - 1) // step_size + 1
            w_out = (w + 2 * padding - (kw - 1) - 1) // step_size + 1
            features_unfolded = features_unfolded.view(b, c + 2, kh * kw, h_out, w_out)

            center_idx = kh * kw // 2
            center_features = features_unfolded[:, :, center_idx:center_idx+1, :, :]

            # 6. Calculate Weights (Vectorized)
            diff = features_unfolded - center_features
            diff_int = diff[:, :c, ...]
            diff_sp = diff[:, c:, ...]

            dist_sq_int = torch.sum(diff_int**2, dim=1, keepdim=True)
            dist_sq_sp = torch.sum(diff_sp**2, dim=1, keepdim=True)

            term_int = dist_sq_int / (sigma_int**2 + 1e-8)
            term_sp = dist_sq_sp / (sigma_sp**2 + 1e-8)
            W = torch.exp(-(term_int + term_sp))

            # 7. Weighted Averaging (Vectorized)
            W_sum = torch.sum(W, dim=2, keepdim=True) + 1e-8
            W_norm = W / W_sum

            updated_features = torch.sum(features_unfolded * W_norm, dim=2)

            current_features = updated_features

    # 8. Final Interpolation
    final_intensities = current_features[:, :c, ...]
    final_coords = current_features[:, c:, ...]

    known_coords = final_coords.squeeze(0).permute(1, 2, 0).reshape(-1, 2).cpu().numpy()
    known_values = final_intensities.squeeze(0).permute(1, 2, 0).reshape(-1, c).cpu().numpy()

    orig_grid_y, orig_grid_x = torch.meshgrid(torch.arange(h, device='cpu'),
                                              torch.arange(w, device='cpu'),
                                              indexing='ij')
    query_coords = torch.stack((orig_grid_y, orig_grid_x), dim=-1).reshape(-1, 2).numpy()

    knn = KNeighborsRegressor(n_neighbors=1)
    knn.fit(known_coords, known_values)
    interpolated_values = knn.predict(query_coords)

    filtered_image_tensor = torch.from_numpy(interpolated_values)\
                                 .reshape(h, w, c).permute(2, 0, 1)\
                                 .unsqueeze(0).to(device)

    return filtered_image_tensor
</pre>
                </div>
            </div>
        </section>

        <!-- Deep Dive Section -->
        <section id="deep-dive" class="py-16">
            <div class="max-w-4xl mx-auto px-6">
                <div class="text-center mb-12">
                    <h2 class="text-3xl font-bold text-slate-800 mb-2">Deep Dive: Further Considerations</h2>
                    <p class="text-lg text-slate-600">The conversion raises some important questions. Here are explanations for key design choices and their implications.</p>
                </div>
                <div class="space-y-4" id="faq-container">
                    <!-- FAQ items will be injected by JS -->
                </div>
            </div>
        </section>

    </main>

    <footer class="bg-slate-800 text-slate-400 py-8">
        <div class="container mx-auto text-center">
            <p>Interactive Report generated from a technical document.</p>
            <p class="text-sm mt-1">Harnessing the power of parallel computing.</p>
        </div>
    </footer>

    <script>
    document.addEventListener('DOMContentLoaded', () => {

        // --- Navigation ---
        const navLinks = document.querySelectorAll('.nav-link');
        const sections = document.querySelectorAll('section');

        const observerOptions = {
            root: null,
            rootMargin: '0px',
            threshold: 0.3
        };

        const observer = new IntersectionObserver((entries) => {
            entries.forEach(entry => {
                if (entry.isIntersecting) {
                    navLinks.forEach(link => {
                        link.classList.remove('nav-active');
                        link.classList.add('nav-inactive');
                        if (link.getAttribute('href').substring(1) === entry.target.id) {
                            link.classList.add('nav-active');
                            link.classList.remove('nav-inactive');
                        }
                    });
                }
            });
        }, observerOptions);

        sections.forEach(section => {
            observer.observe(section);
        });

        // --- Unfold Diagram ---
        const unfoldDiagram = document.getElementById('unfold-diagram');
        const wsizeSlider = document.getElementById('wsize-slider');
        const wsizeLabel = document.getElementById('wsize-label');

        function createUnfoldDiagram(wsize) {
            unfoldDiagram.innerHTML = '';
            const gridSize = 8;
            for (let i = 0; i < gridSize * gridSize; i++) {
                const cell = document.createElement('div');
                cell.classList.add('bg-slate-300', 'patch');
                unfoldDiagram.appendChild(cell);
            }
            const overlay = document.createElement('div');
            overlay.style.position = 'absolute';
            overlay.style.top = '25%';
            overlay.style.left = '37.5%';
            overlay.style.width = `${(wsize / gridSize) * 100}%`;
            overlay.style.height = `${(wsize / gridSize) * 100}%`;
            overlay.style.border = '2px solid #f59e0b';
            overlay.style.backgroundColor = 'rgba(245, 158, 11, 0.2)';
            overlay.classList.add('rounded-sm');
            unfoldDiagram.appendChild(overlay);
        }

        wsizeSlider.addEventListener('input', (e) => {
            const size = parseInt(e.target.value);
            wsizeLabel.textContent = `${size}x${size}`;
            createUnfoldDiagram(size);
        });

        createUnfoldDiagram(parseInt(wsizeSlider.value));

        // --- Step-by-Step Tabs ---
        const stepTabs = document.querySelectorAll('.step-tab');
        const stepContentEl = document.getElementById('step-content');
        const stepData = {
            '1': {
                title: '1. Create a Combined Feature Tensor',
                description: "The first step is to create a unified data structure. We concatenate the image's intensity channels (e.g., R, G, B) with its spatial coordinates (Y, X). This creates a 5D feature vector (R, G, B, Y, X) for every pixel, allowing the algorithm to consider both color and location similarity in a single operation.",
                diagram: `
                    <div class="flex items-center justify-center gap-2">
                        <div class="text-center p-4 bg-blue-100 rounded-lg shadow">
                            <h4 class="font-bold">Intensity (C)</h4>
                            <p>[R, G, B]</p>
                        </div>
                        <div class="text-2xl font-bold">+</div>
                         <div class="text-center p-4 bg-green-100 rounded-lg shadow">
                            <h4 class="font-bold">Coordinates (2)</h4>
                            <p>[Y, X]</p>
                        </div>
                        <div class="text-2xl font-bold">=</div>
                        <div class="text-center p-4 bg-amber-100 rounded-lg shadow">
                            <h4 class="font-bold">Feature Vector (C+2)</h4>
                             <p>[R, G, B, Y, X]</p>
                        </div>
                    </div>`
            },
            '2': {
                title: '2. Unfold to Extract Patches',
                description: 'Using `unfold`, we extract a local neighborhood (patch) for every pixel location in a single, parallel operation. The result is a large tensor where for each pixel, we have direct access to all its neighbors\' feature vectors without needing a loop.',
                diagram: `<div class="w-full h-48 diagram-box rounded-lg flex items-center justify-center text-slate-500 font-semibold p-4">This step is visualized in "The Solution" section above. It transforms the (B, C+2, H, W) tensor into a (B, (C+2)*k*k, L) tensor.</div>`
            },
            '3': {
                title: '3. Calculate Weights in Parallel',
                description: 'Now that we have all patches, we can compute the meanshift weights simultaneously for every pixel. We subtract the center pixel\'s feature vector from all its neighbors\' vectors, calculate the squared distance for intensity and space, apply the Gaussian kernel formula, and get all weights in one go.',
                diagram: `
                    <div class="text-center">
                        <p class="font-mono text-sm bg-slate-200 p-2 rounded">W = exp( -(dist_int² / σ_int²) - (dist_sp² / σ_sp²) )</p>
                        <p class="mt-4">This formula is applied to millions of data points at once using vectorized tensor math.</p>
                    </div>`
            },
            '4': {
                title: '4. Compute Weighted Average',
                description: 'With the weights calculated, we find the new position (the "mean shift") for each pixel. This is a weighted average of its neighbors\' feature vectors (both intensity and coordinates). This operation is also fully vectorized, performing a weighted sum and normalization across all patches in parallel.',
                diagram: `
                    <div class="text-center">
                        <p class="font-mono text-sm bg-slate-200 p-2 rounded">New_Feature = Σ(W * Neighbor_Feature) / Σ(W)</p>
                        <p class="mt-4">This updates every pixel's intensity and coordinates, moving them towards the local mode of the data density.</p>
                    </div>`
            },
            '5': {
                title: '5. Interpolate Back to Grid',
                description: 'After several iterations, the pixels\' spatial coordinates will have shifted and may no longer form a regular grid. The final step uses an interpolation method (like k-Nearest Neighbors) to sample the calculated intensity values at the drifted coordinates and map them back onto the original, regular image grid, producing the final filtered image.',
                 diagram: `
                    <div class="flex items-center justify-center gap-4">
                        <div class="w-24 h-24 diagram-box flex items-center justify-center text-center p-2 text-sm font-semibold">Scattered<br>Points</div>
                        <div class="text-2xl font-bold">&rarr;</div>
                        <div class="w-24 h-24 bg-slate-800 grid grid-cols-4 grid-rows-4 p-1 gap-px rounded-md flex items-center justify-center text-center p-2 text-sm font-semibold text-white">Regular<br>Grid</div>
                    </div>`
            },
        };

        function updateStepContent(step) {
            const content = stepData[step];
            stepContentEl.innerHTML = `
                <div class="prose">
                    <h3 class="font-semibold text-xl text-slate-800 mb-4">${content.title}</h3>
                    <p class="text-slate-600">${content.description}</p>
                </div>
                <div class="flex items-center justify-center p-4 min-h-[200px]">${content.diagram}</div>
            `;
        }

        stepTabs.forEach(tab => {
            tab.addEventListener('click', () => {
                stepTabs.forEach(t => {
                    t.classList.remove('tab-active');
                    t.classList.add('tab-inactive');
                });
                tab.classList.add('tab-active');
                tab.classList.remove('tab-inactive');
                updateStepContent(tab.dataset.step);
            });
        });

        updateStepContent('1');

        // --- Performance Chart ---
        const imageSizeSlider = document.getElementById('image-size-slider');
        const iterationsSlider = document.getElementById('iterations-slider');
        const imageSizeLabel = document.getElementById('image-size-label');
        const iterationsLabel = document.getElementById('iterations-label');

        const ctx = document.getElementById('perfChart').getContext('2d');
        const perfChart = new Chart(ctx, {
            type: 'bar',
            data: {
                labels: ['NumPy (CPU)', 'PyTorch (GPU)'],
                datasets: [{
                    label: 'Relative Processing Time (ms)',
                    data: [100, 1],
                    backgroundColor: [
                        'rgba(248, 113, 113, 0.6)',
                        'rgba(52, 211, 153, 0.6)'
                    ],
                    borderColor: [
                        'rgba(248, 113, 113, 1)',
                        'rgba(52, 211, 153, 1)'
                    ],
                    borderWidth: 1
                }]
            },
            options: {
                indexAxis: 'y',
                maintainAspectRatio: false,
                scales: {
                    x: {
                        beginAtZero: true,
                        type: 'logarithmic',
                        title: {
                            display: true,
                            text: 'Relative Time (Log Scale)'
                        }
                    }
                },
                plugins: {
                    legend: { display: false },
                    tooltip: {
                         callbacks: {
                            label: function(context) {
                                return `Relative Time: ${context.raw.toFixed(2)} ms`;
                            }
                        }
                    }
                }
            }
        });

        function updatePerfChart() {
            const imageSize = parseInt(imageSizeSlider.value);
            const iterations = parseInt(iterationsSlider.value);

            imageSizeLabel.textContent = imageSize.toLocaleString();
            iterationsLabel.textContent = iterations;

            const numpyTime = (imageSize / 1000) * iterations * 0.5; // Base factor
            const pytorchTime = (Math.log10(imageSize) * Math.log10(iterations) * 0.1) + 5;

            perfChart.data.datasets[0].data[0] = numpyTime;
            perfChart.data.datasets[0].data[1] = pytorchTime;
            perfChart.update();
        }

        imageSizeSlider.addEventListener('input', updatePerfChart);
        iterationsSlider.addEventListener('input', updatePerfChart);

        updatePerfChart();

        // --- Deep Dive (FAQ) ---
        const faqContainer = document.getElementById('faq-container');
        const faqData = [
            {
                q: "Why not use Conv2d / Conv3d?",
                a: "Standard convolutional layers are unsuitable because they use fixed, data-independent kernels. Meanshift filtering is data-dependent: the weight applied to a neighbor depends on the intensity values of both the neighbor and the center pixel. This makes the filter non-linear and spatially variant in a way that `Conv2d` cannot capture. `unfold` followed by manual weight calculation is the correct vectorized approach."
            },
            {
                q: "What about the original code's stochastic subsampling?",
                a: "The original NumPy code randomly subsampled neighbors, making the output non-deterministic and complicating vectorization. The PyTorch version uses the full, deterministic window of neighbors. This aligns with standard meanshift formulations, produces consistent results, and is essential for the efficient `unfold` strategy."
            },
            {
                q: "What are the memory implications?",
                a: "The `unfold` operation creates a large intermediate tensor that holds all the patches. Its size can be significant for very large images or large window sizes, potentially consuming a lot of GPU memory. This is a classic trade-off: we use more memory to gain a massive speedup in computation."
            },
            {
                q: "Why use k-NN for interpolation?",
                a: "After the meanshift iterations, the updated pixel coordinates are no longer on a regular grid. `KNeighborsRegressor` (with k=1) is a practical and effective way to map these intensity values from their new, scattered locations back onto the original image grid, functionally replacing `scipy.NearestNDInterpolator` from the NumPy version."
            }
        ];

        faqData.forEach(item => {
            const div = document.createElement('div');
            div.classList.add('bg-white', 'rounded-lg', 'shadow-sm', 'overflow-hidden');
            div.innerHTML = `
                <button class="w-full text-left p-4 flex justify-between items-center font-semibold text-slate-800 hover:bg-slate-100 transition-colors focus:outline-none">
                    <span>${item.q}</span>
                    <span class="transform transition-transform duration-200 faq-arrow">&darr;</span>
                </button>
                <div class="faq-answer hidden p-4 border-t border-slate-200 text-slate-600">
                    <p>${item.a}</p>
                </div>
            `;
            faqContainer.appendChild(div);
        });

        faqContainer.addEventListener('click', (e) => {
            const button = e.target.closest('button');
            if (button) {
                const answer = button.nextElementSibling;
                const arrow = button.querySelector('.faq-arrow');
                answer.classList.toggle('hidden');
                arrow.classList.toggle('rotate-180');
            }
        });

    });
    </script>
</body>
</html>
